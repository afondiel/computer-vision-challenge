# L2 - 02: Text to Image Synthesis with LLMs and LVLMs

## Overview

Text to Image Synthesis with Large Language Models (LLMs) and Large Vision-Language Models (LVLMs).

**Implementation Pipeline**
- Setup Environment
- Install Dependencies
- Load Pre-trained CLIP Model
- Generate Images Based on Text Descriptions

## Contributing

If you want to contribute to this project, you are welcome to do so. You can either add new projects, improve existing ones, or fix bugs and errors. 

Please follow these steps to contribute:

- Fork this repository and clone it to your local machine.
- Create a new branch with a descriptive name for your contribution.
- Add your code and files to the branch and commit your changes.
- Push your branch to your forked repository and create a pull request to the main repository.
- Wait for your pull request to be reviewed and merged.

## References

- [Vision LLMs - Notes](https://github.com/afondiel/computer-science-notes/tree/master/computer-vision-notes/vision-llms)
- [How Stable Diffusion Works (AI Image Generation) - Gonkee (Must Watch)](https://www.youtube.com/watch?v=sFztPP9qPRc)
- [Generative Adversarial Text to Image Synthesis - paper (2016)](https://arxiv.org/pdf/1605.05396.pdf)
- [A Survey and Taxonomy of Adversarial Neural Networks for Text-to-Image Synthesis - paper (2019)](https://arxiv.org/pdf/1910.09399.pdf)
- [DiffusionGPT: LLM-Driven Text-to-Image Generation System - paper (2024)](https://arxiv.org/pdf/2401.10061.pdf)
- [DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation](https://dreambooth.github.io/)

Papers:
- [Enhancing Large Vision Language Models with Self-Training on Image Comprehension - May.2024](https://arxiv.org/pdf/2405.19716)
- [LVLM-eHub: A Comprehensive Evaluation Benchmark for Large Vision-Language Models](https://arxiv.org/abs/2306.09265)

