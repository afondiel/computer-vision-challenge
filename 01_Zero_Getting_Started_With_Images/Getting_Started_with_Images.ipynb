{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:black\">Getting Started with Images</font>\n",
    "This notebook will help you take your first steps in learning Image Processing and Computer Vision using OpenCV. You will learn some important lessons using some simple examples. In this notebook, you will learn the following:\n",
    "\n",
    "* Reading an image \n",
    "* Check image attributes like datatype and shape \n",
    "* Matrix representation of an image in Numpy\n",
    "* Color Images and splitting/merging image channels\n",
    "* Displaying images using matplotlib\n",
    "* Saving images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  <font style=\"color:black\">Import Libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <font style=\"color:black\">Display Image Directly</font>\n",
    "We will use the following as our sample images. We will use the ipython image function to load and display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABIAAAASCAAAAABzpdGLAAAATElEQVQYGR3BgQ0AAAyDIP3/6C4O5I1I5I1I5I1I5I1I5I1I5I1IHJGMOCIZcUQy4ohkxBHJiCOSEXkjEnkjEnkjEnkjEnkjEnkjkgNOnhgN4+xtIgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display 18x18 pixel image.\n",
    "Image(filename='checkerboard_18x18.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display 84x84 pixel image.\n",
    "Image(filename='checkerboard_84x84.jpg') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# <font style=\"color:black\">Reading images using OpenCV</font>\n",
    "\n",
    "OpenCV allows reading different types of images (JPG, PNG, etc). You can load grayscale images, color images or you can also load images with Alpha channel. It uses the **`cv2.imread()`** function which has the following syntax:\n",
    "\n",
    "### <font color=\"green\">Function Syntax </font>\n",
    "``` python\n",
    "retval = cv2.imread( filename[, flags] )\n",
    "```\n",
    "\n",
    "`retval`: Is the image if it is successfully loaded. Otherwise it is `None`. This may happen if the filename is wrong or the file is corrupt.\n",
    "\n",
    "The function has **1 required input argument** and one optional flag:\n",
    "\n",
    "\n",
    "1. `filename`: This can be an **absolute** or **relative** path. This is a **mandatory argument**.\n",
    "2. `Flags`:    These flags are used to read an image in a particular format (for example, grayscale/color/with alpha channel). This is an **optional argument** with a default value of `cv2.IMREAD_COLOR` or `1` which loads the image as a color image.\n",
    "\n",
    "Before we proceed with some examples, let's also have a look at some of the `flags` available.\n",
    "\n",
    "**Flags**\n",
    "1. **`cv2.IMREAD_GRAYSCALE`** or **`0`**: Loads image in grayscale mode\n",
    "2. **`cv2.IMREAD_COLOR`** or **`1`**: Loads a color image. Any transparency of image will be neglected. It is the default flag.\n",
    "3. **`cv2.IMREAD_UNCHANGED`** or **`-1`**: Loads image as such including alpha channel.\n",
    "\n",
    "\n",
    "### <font color=\"green\">OpenCV Documentation</font>\n",
    "\n",
    "**`Imread:`**https://docs.opencv.org/4.5.1/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56\n",
    "\n",
    "**`ImreadModes:`** https://docs.opencv.org/4.5.1/d8/d6a/group__imgcodecs__flags.html#ga61d9b0126a3e57d9277ac48327799c80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]\n",
      " [255 255 255 255 255 255   0   0   0   0   0   0 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255   0   0   0   0   0   0 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255   0   0   0   0   0   0 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255   0   0   0   0   0   0 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255   0   0   0   0   0   0 255 255 255 255 255 255]\n",
      " [255 255 255 255 255 255   0   0   0   0   0   0 255 255 255 255 255 255]\n",
      " [  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 255 255 255 255 255 255   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# Read image as gray scale.\n",
    "cb_img = cv2.imread(\"checkerboard_18x18.png\",0)\n",
    "\n",
    "# Print the image data (pixel values), element of a 2D numpy array.\n",
    "# Each pixel value is 8-bits [0,255]\n",
    "print(cb_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Image attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# print the size  of image\n",
    "print(\"Image size is \", cb_img.shape)\n",
    "\n",
    "# print data-type of image\n",
    "print(\"Data type of image is \", cb_img.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Images using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Display image.\n",
    "plt.imshow(cb_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened?\n",
    "Even though the image was read in as a gray scale image, it won't necessarily display in gray scale when using `imshow()`. matplotlib uses different color maps and it's possible that the gray scale color map is not set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color map to gray scale for proper rendering.\n",
    "plt.imshow(cb_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image as gray scale.\n",
    "cb_img_fuzzy = cv2.imread(\"checkerboard_fuzzy_18x18.jpg\",0)\n",
    "\n",
    "# print image\n",
    "print(cb_img_fuzzy)\n",
    "\n",
    "# Display image.\n",
    "plt.imshow(cb_img_fuzzy,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Color Images\n",
    "Until now, we have been using gray scale images in our discussion. Let us now discuss color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Read and display Coca-Cola logo.\n",
    "Image(\"coca-cola-logo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and display color image\n",
    "Let us read a color image and check the parameters. Note the image dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in image\n",
    "coke_img = cv2.imread(\"coca-cola-logo.png\",1)\n",
    "\n",
    "# print the size  of image\n",
    "print(\"Image size is \", coke_img.shape)\n",
    "\n",
    "# print data-type of image\n",
    "print(\"Data type of image is \", coke_img.dtype)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(coke_img)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#  What happened?\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(coke_img)\n",
    "#  What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The color displayed above is different from the actual image. This is because matplotlib expects the image in RGB format whereas OpenCV stores images in BGR format. Thus, for correct display, we need to reverse the channels of the image. We will discuss about the channels in the sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'coke_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m coke_img_channels_reversed \u001b[38;5;241m=\u001b[39m \u001b[43mcoke_img\u001b[49m[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(coke_img_channels_reversed)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'coke_img' is not defined"
     ]
    }
   ],
   "source": [
    "coke_img_channels_reversed = coke_img[:, :, ::-1]\n",
    "plt.imshow(coke_img_channels_reversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Merging Color Channels\n",
    "\n",
    "\n",
    "**`cv2.split()`** Divides a multi-channel array into several single-channel arrays.\n",
    "\n",
    "**`cv2.merge()`** Merges several arrays to make a single multi-channel array. All the input matrices must have the same size.\n",
    "\n",
    "### <font style=\"color:rgb(8,133,37)\">OpenCV Documentation</font>\n",
    "\n",
    "https://docs.opencv.org/4.5.1/d2/de8/group__core__array.html#ga0547c7fed86152d7e9d0096029c8518a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Split the image into the B,G,R components\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img_NZ_bgr \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew_Zealand_Lake.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m      3\u001b[0m b,g,r \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39msplit(img_NZ_bgr)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Show the channels\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# Split the image into the B,G,R components\n",
    "img_NZ_bgr = cv2.imread(\"New_Zealand_Lake.jpg\",cv2.IMREAD_COLOR)\n",
    "b,g,r = cv2.split(img_NZ_bgr)\n",
    "\n",
    "# Show the channels\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.subplot(141);plt.imshow(r,cmap='gray');plt.title(\"Red Channel\");\n",
    "plt.subplot(142);plt.imshow(g,cmap='gray');plt.title(\"Green Channel\");\n",
    "plt.subplot(143);plt.imshow(b,cmap='gray');plt.title(\"Blue Channel\");\n",
    "\n",
    "# Merge the individual channels into a BGR image\n",
    "imgMerged = cv2.merge((b,g,r))\n",
    "# Show the merged output\n",
    "plt.subplot(144);plt.imshow(imgMerged[:,:,::-1]);plt.title(\"Merged Output\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to different Color Spaces\n",
    "\n",
    "\n",
    "**`cv2.cvtColor()`** Converts an image from one color space to another. The function converts an input image from one color space to another. In case of a transformation to-from RGB color space, the order of the channels should be specified explicitly (RGB or BGR). Note that the default color format in OpenCV is often referred to as RGB but it is actually BGR (the bytes are reversed). So the first byte in a standard (24-bit) color image will be an 8-bit Blue component, the second byte will be Green, and the third byte will be Red. The fourth, fifth, and sixth bytes would then be the second pixel (Blue, then Green, then Red), and so on.\n",
    "\n",
    "### <font style=\"color:rgb(8,133,37)\">Function Syntax </font>\n",
    "``` python\n",
    "dst = cv2.cvtColor( src, code )\n",
    "```\n",
    "\n",
    "`dst`: Is the output image of the same size and depth as `src`.\n",
    "\n",
    "The function has **2 required arguments**:\n",
    "\n",
    "1. `src` input image: 8-bit unsigned, 16-bit unsigned ( CV_16UC... ), or single-precision floating-point.\n",
    "2. `code` color space conversion code (see ColorConversionCodes). \n",
    "\n",
    "### <font style=\"color:rgb(8,133,37)\">OpenCV Documentation</font>\n",
    "\n",
    "**`cv2.cvtColor:`** https://docs.opencv.org/3.4/d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab\n",
    "**`ColorConversionCodes:`** https://docs.opencv.org/4.5.1/d8/d01/group__imgproc__color__conversions.html#ga4e0972be5de079fed4e3a10e24ef5ef0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing from BGR to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# OpenCV stores color channels in a differnet order than most other applications (BGR vs RGB).\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img_NZ_rgb \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mcvtColor(img_NZ_bgr, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img_NZ_rgb)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# OpenCV stores color channels in a differnet order than most other applications (BGR vs RGB).\n",
    "img_NZ_rgb = cv2.cvtColor(img_NZ_bgr, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img_NZ_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing to HSV color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img_hsv \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mcvtColor(img_NZ_bgr, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Split the image into the B,G,R components\u001b[39;00m\n\u001b[0;32m      3\u001b[0m h,s,v \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39msplit(img_hsv)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "img_hsv = cv2.cvtColor(img_NZ_bgr, cv2.COLOR_BGR2HSV)\n",
    "# Split the image into the B,G,R components\n",
    "h,s,v = cv2.split(img_hsv)\n",
    "\n",
    "# Show the channels\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.subplot(141);plt.imshow(h,cmap='gray');plt.title(\"H Channel\");\n",
    "plt.subplot(142);plt.imshow(s,cmap='gray');plt.title(\"S Channel\");\n",
    "plt.subplot(143);plt.imshow(v,cmap='gray');plt.title(\"V Channel\");\n",
    "plt.subplot(144);plt.imshow(img_NZ_rgb);plt.title(\"Original\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying individual Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h_new \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      2\u001b[0m img_NZ_merged \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mmerge((h_new,s,v))\n\u001b[0;32m      3\u001b[0m img_NZ_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img_NZ_merged, cv2\u001b[38;5;241m.\u001b[39mCOLOR_HSV2RGB)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "h_new = h+10\n",
    "img_NZ_merged = cv2.merge((h_new,s,v))\n",
    "img_NZ_rgb = cv2.cvtColor(img_NZ_merged, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "# Show the channels\n",
    "plt.figure(figsize=[20,5])\n",
    "plt.subplot(141);plt.imshow(h,cmap='gray');plt.title(\"H Channel\");\n",
    "plt.subplot(142);plt.imshow(s,cmap='gray');plt.title(\"S Channel\");\n",
    "plt.subplot(143);plt.imshow(v,cmap='gray');plt.title(\"V Channel\");\n",
    "plt.subplot(144);plt.imshow(img_NZ_rgb);plt.title(\"Modified\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Images\n",
    "\n",
    "Saving the image is as trivial as reading an image in OpenCV. We use the function **`cv2.imwrite()`** with two arguments. The first one is the filename, second argument is the image object.\n",
    "\n",
    "The function imwrite saves the image to the specified file. The image format is chosen based on the filename extension (see cv::imread for the list of extensions). In general, only 8-bit single-channel or 3-channel (with 'BGR' channel order) images can be saved using this function (see the OpenCV documentation for further details).\n",
    "\n",
    "\t\n",
    "### <font style=\"color:rgb(8,133,37)\">Function Syntax </font>\n",
    "``` python\n",
    "cv2.imwrite( filename, img[, params] )\n",
    "```\n",
    "\n",
    "The function has **2 required arguments**:\n",
    "\n",
    "1. `filename`: This can be an **absolute** or **relative** path. \n",
    "2. `img`: Image or Images to be saved.\n",
    "\n",
    "### <font style=\"color:rgb(8,133,37)\">OpenCV Documentation</font>\n",
    "\n",
    "**`Imwrite:`** https://docs.opencv.org/4.5.1/d4/da8/group__imgcodecs.html#gabbc7ef1aa2edfaa87772f1202d67e0ce\n",
    "**`ImwriteFlags:`**https://docs.opencv.org/4.5.1/d8/d6a/group__imgcodecs__flags.html#ga292d81be8d76901bff7988d18d2b42ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# save the image\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew_Zealand_Lake_SAVED.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, img_NZ_bgr)\n\u001b[0;32m      4\u001b[0m Image(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNew_Zealand_Lake_SAVED.png\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# save the image\n",
    "cv2.imwrite(\"New_Zealand_Lake_SAVED.png\", img_NZ_bgr)\n",
    "\n",
    "Image(filename='New_Zealand_Lake_SAVED.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# read the image as Color\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img_NZ_bgr \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew_Zealand_Lake_SAVED.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_NZ_bgr shape is: \u001b[39m\u001b[38;5;124m\"\u001b[39m, img_NZ_bgr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# read the image as Grayscaled\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# read the image as Color\n",
    "img_NZ_bgr = cv2.imread(\"New_Zealand_Lake_SAVED.png\", cv2.IMREAD_COLOR)\n",
    "print(\"img_NZ_bgr shape is: \", img_NZ_bgr.shape)\n",
    "\n",
    "# read the image as Grayscaled\n",
    "img_NZ_gry = cv2.imread(\"New_Zealand_Lake_SAVED.png\", cv2.IMREAD_GRAYSCALE)\n",
    "print(\"img_NZ_gry shape is: \", img_NZ_gry.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
